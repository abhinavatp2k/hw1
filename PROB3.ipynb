{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Define the categories\n",
    "categories = [\n",
    "    \"alt.atheism\", \n",
    "    \"sci.med\", \n",
    "    \"sci.electronics\", \n",
    "    \"comp.graphics\", \n",
    "    \"talk.politics.guns\", \n",
    "    \"sci.crypt\"\n",
    "]\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups_data = fetch_20newsgroups(\n",
    "    subset='all', \n",
    "    categories=categories, \n",
    "    shuffle=True, \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data and the target labels\n",
    "X = newsgroups_data.data\n",
    "y = newsgroups_data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming X is your text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5647, 62583)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4517, 62583)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'vectors' is your feature matrix and 'y' is your target array\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(vectors.shape[0] * 0.8)  # 80% for training\n",
    "\n",
    "# Shuffle the dataset (optional, similar to random_state in train_test_split)\n",
    "indices = np.arange(vectors.shape[0])\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "vectors_shuffled = vectors[indices]\n",
    "y_shuffled = y[indices]\n",
    "\n",
    "# Manually split the dataset\n",
    "X_train = vectors_shuffled[:split_index]\n",
    "y_train = y_shuffled[:split_index]\n",
    "X_test = vectors_shuffled[split_index:]\n",
    "y_test = y_shuffled[split_index:]\n",
    "\n",
    "# Output the shape of X_train\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4492)\t0.003350647189648428\n",
      "  (0, 3949)\t0.007127312793135944\n",
      "  (0, 3685)\t0.03252263107640067\n",
      "  (0, 3593)\t0.012175881753406528\n",
      "  (0, 3323)\t0.03131988820594425\n",
      "  (0, 3145)\t0.009165790196926593\n",
      "  (0, 2945)\t0.009698642534557557\n",
      "  (0, 2879)\t0.0015630076102292763\n",
      "  (0, 2697)\t0.03518546366335293\n",
      "  (0, 2293)\t0.010475920306978723\n",
      "  (0, 2002)\t0.004776067750334571\n",
      "  (0, 1260)\t0.006319514189957893\n",
      "  (0, 1257)\t0.014915520491031608\n",
      "  (0, 1069)\t0.019427232533151123\n",
      "  (0, 906)\t0.0064815167558430285\n",
      "  (0, 33)\t0.006863852776260209\n",
      "  (0, 3589)\t0.024161220596529115\n",
      "  (0, 3578)\t0.010995453178862798\n",
      "  (0, 3499)\t0.020734466894671025\n",
      "  (0, 3456)\t0.032214599013786864\n",
      "  (0, 3096)\t0.042565932729921103\n",
      "  (0, 2880)\t0.01507003251099234\n",
      "  (0, 2696)\t0.018914592849813797\n",
      "  (0, 2162)\t0.03902415907002439\n",
      "  (0, 2097)\t0.01683361989203393\n",
      "  :\t:\n",
      "  (4516, 481)\t0.14441631958667075\n",
      "  (4516, 480)\t0.17267382990792615\n",
      "  (4516, 471)\t0.09724836671974504\n",
      "  (4516, 466)\t0.11644317825398529\n",
      "  (4516, 436)\t0.032902055533852385\n",
      "  (4516, 431)\t0.06647931532231119\n",
      "  (4516, 409)\t0.08466993790216942\n",
      "  (4516, 376)\t0.09959338531378555\n",
      "  (4516, 348)\t0.01315461122389527\n",
      "  (4516, 306)\t0.08281751642123461\n",
      "  (4516, 276)\t0.1520453998997524\n",
      "  (4516, 256)\t0.07356561387968924\n",
      "  (4516, 250)\t0.03988691888174986\n",
      "  (4516, 237)\t0.045031060894140475\n",
      "  (4516, 214)\t0.06791745935533103\n",
      "  (4516, 206)\t0.05128395753122917\n",
      "  (4516, 174)\t0.07652142292628993\n",
      "  (4516, 156)\t0.17300444539220097\n",
      "  (4516, 142)\t0.07699936522528421\n",
      "  (4516, 108)\t0.03507215773334278\n",
      "  (4516, 105)\t0.05595911776288218\n",
      "  (4516, 78)\t0.09585750905729236\n",
      "  (4516, 74)\t0.06413025091575615\n",
      "  (4516, 27)\t0.06535152159972227\n",
      "  (4516, 2)\t0.09394675653206537\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def manual_cosine_similarity(matrix):\n",
    "    # Ensure the matrix is in CSR format\n",
    "    if not isinstance(matrix, csr_matrix):\n",
    "        matrix = matrix.tocsr()\n",
    "\n",
    "    # Normalize the matrix rows to unit vectors\n",
    "    norms = np.sqrt(matrix.power(2).sum(axis=1))\n",
    "    normalized_matrix = matrix.multiply(1.0 / norms)\n",
    "\n",
    "    # Compute the cosine similarity as dot product of normalized vectors\n",
    "    return normalized_matrix @ normalized_matrix.T\n",
    "\n",
    "# Assuming X_train is a sparse matrix from TfidfVectorizer\n",
    "cosine_sim_manual = manual_cosine_similarity(X_train)\n",
    "\n",
    "# Output the cosine similarity matrix\n",
    "print(cosine_sim_manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.38549948 1.34140515 ... 1.32964123 1.39802425 1.31584736]\n",
      " [1.38549948 0.         1.38698005 ... 1.38907098 1.39907044 1.37120861]\n",
      " [1.34140515 1.38698005 0.         ... 1.35229645 1.40204639 1.34614505]\n",
      " ...\n",
      " [1.32964123 1.38907098 1.35229645 ... 0.         1.399969   1.34452709]\n",
      " [1.39802425 1.39907044 1.40204639 ... 1.399969   0.         1.39816546]\n",
      " [1.31584736 1.37120861 1.34614505 ... 1.34452709 1.39816546 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Assuming X_train is your feature matrix\n",
    "dist_mat = euclidean_distances(X_train)\n",
    "\n",
    "# Output the Euclidean distance matrix\n",
    "print(dist_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.01769911504424%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.train_x = X\n",
    "        self.train_y = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Compute the cosine similarity between X and train_x\n",
    "        sim = cosine_similarity(X, self.train_x)\n",
    "\n",
    "        # Get indices of k nearest neighbors\n",
    "        top_k_indices = np.argsort(sim, axis=1)[:, -self.k:]\n",
    "\n",
    "        # Get labels of k nearest neighbors\n",
    "        top_k_labels = self.train_y[top_k_indices]\n",
    "\n",
    "        # Predict the mode of the labels for each instance\n",
    "        return mode(top_k_labels, axis=1).mode.flatten()\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = np.mean(predictions == y)\n",
    "        return accuracy * 100\n",
    "\n",
    "# Usage\n",
    "knn_clf = KNNClassifier(k=10)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {knn_clf.score(X_test, y_test)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.01769911504424"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import mode\n",
    "knn_clf = KNNClassifier(k=10)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "knn_clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
